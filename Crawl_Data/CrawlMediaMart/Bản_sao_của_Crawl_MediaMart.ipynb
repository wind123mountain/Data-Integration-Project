{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0a7sxDo9ddx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def crawl_item(url_input):\n",
        "  try:\n",
        "    url = 'https://mediamart.vn' + url_input\n",
        "    headers = {\n",
        "      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "      'X-Requested-With': 'XMLHttpRequest',\n",
        "    }    \n",
        "    r = requests.get(url, headers=headers)\n",
        "    data = {}\n",
        "    soup = BeautifulSoup(r.content.decode('utf-8', 'ignore'), 'html.parser')\n",
        "    data[\"name\"] = soup.find_all(\"div\", class_=\"pdetail-name\")[0].text.split('\\n')[1]\n",
        "    x=0\n",
        "    key=''\n",
        "    for tr in soup.find_all('td'):\n",
        "      if(len(tr.get_text()) > 0):\n",
        "        if(x%2)==0:\n",
        "          key=tr.get_text()\n",
        "        else:\n",
        "          data[key]=tr.get_text()\n",
        "        x=x+1\n",
        "    data[\"price\"] = soup.find(\"div\", class_=\"pdetail-price-box\").text\n",
        "    time.sleep(10)\n",
        "    return data\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "def crawl_mediaMart():\n",
        "  data=[]\n",
        "  df = pd.read_csv('mediamart.csv') #duong dan file csv\n",
        "  url = 'https://mediamart.vn/smartphones'\n",
        "  headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "    'X-Requested-With': 'XMLHttpRequest',\n",
        "  }    \n",
        "  r = requests.get(url, headers=headers)\n",
        "  soup = BeautifulSoup(r.content, 'html.parser')\n",
        "  for div in soup.find_all(\"div\", class_=\"col-6 col-md-3 col-lg-3\"):\n",
        "    data.append(crawl_item(div.find(\"a\", href=True)['href']))\n",
        "  pd.concat([pd.DataFrame(data), df], ignore_index=True)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyoHqimE3M3A",
        "outputId": "ba859b3d-e33b-479a-8d07-5bcb58c03c30"
      },
      "outputs": [],
      "source": [
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch_wDBW4j__p",
        "outputId": "66d33bcc-06eb-4d9e-a307-883e8e9568a0"
      },
      "outputs": [],
      "source": [
        "url = 'https://mediamart.vn/smartphones/apple-iphone-11-64gb-white'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "    'X-Requested-With': 'XMLHttpRequest',\n",
        "}    \n",
        "r = requests.get(url, headers=headers)\n",
        "data = {}\n",
        "soup = BeautifulSoup(r.content.decode('utf-8', 'ignore'), 'html.parser')\n",
        "\n",
        "data[\"name\"] = soup.find_all(\"div\", class_=\"pdetail-name\")[0].text.split('\\n')[1]\n",
        "x=0\n",
        "key=''\n",
        "for tr in soup.find_all('td'):\n",
        "  if(len(tr.get_text()) > 0):\n",
        "    if(x%2)==0:\n",
        "      key=tr.get_text()\n",
        "    else:\n",
        "      data[key]=tr.get_text()\n",
        "    x=x+1\n",
        "data[\"price\"] = soup.find(\"div\", class_=\"pdetail-price-box\").text\n",
        "print(data)\n",
        "jsonString = json.dumps(data, ensure_ascii=False)\n",
        "jsonFile = open(\"/content/drive/MyDrive/Colab Notebooks/Media_mart/1.json\", \"w\")\n",
        "jsonFile.write(jsonString)\n",
        "jsonFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEq8pFTzkpxu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "f = open(\"./Media_Mart.txt\", \"r\")\n",
        "soup = BeautifulSoup(f.read(), 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEpDu3vrNvbO",
        "outputId": "dbd8c71f-ea12-4818-90b0-41d227e4678f"
      },
      "outputs": [],
      "source": [
        "soup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ9OgvmkObXO"
      },
      "outputs": [],
      "source": [
        "images_link = []\n",
        "for img in soup.find_all(\"div\", class_ = \"card-img-top\"):\n",
        "  images_link.append(img.find(\"img\")['src'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Gx4Qr-PCs_"
      },
      "outputs": [],
      "source": [
        "images_link = images_link[:147]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYYZP-2wPPOz",
        "outputId": "0a1c3be0-87d3-456c-a482-ec2b3c646221"
      },
      "outputs": [],
      "source": [
        "len(soup.find_all(\"div\", class_=\"col-6 col-md-3 col-lg-3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ELN-Q-BlA9e",
        "outputId": "3e4a9ab9-1d76-449f-9711-05996000fc7b"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "k = 0\n",
        "with open(\"Media_Mart.txt\", mode = \"w\", encoding = \"utf8\") as f:\n",
        "  for div in soup.find_all(\"div\", class_=\"col-6 col-md-3 col-lg-3\"):\n",
        "    try:\n",
        "      url = 'https://mediamart.vn' + div.find(\"a\", href=True)['href']\n",
        "      headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "        'X-Requested-With': 'XMLHttpRequest',\n",
        "      }    \n",
        "      r = requests.get(url, headers=headers)\n",
        "      data = {}\n",
        "      detail = BeautifulSoup(r.content.decode('utf-8', 'ignore'), 'html.parser')\n",
        "      data[\"name\"] = detail.find_all(\"div\", class_=\"pdetail-name\")[0].text.split('\\n')[1]\n",
        "      data[\"url\"] = url\n",
        "      data[\"image_link\"] = images_link[k]\n",
        "      x=0\n",
        "      key=''\n",
        "      for tr in detail.find_all('td'):\n",
        "        if(len(tr.get_text()) > 0):\n",
        "          if(x%2)==0:\n",
        "            key=tr.get_text()\n",
        "          else:\n",
        "            data[key]=tr.get_text()\n",
        "          x=x+1\n",
        "      data[\"price\"] = detail.find(\"div\", class_=\"pdetail-price-box\").text\n",
        "      jsonString = json.dumps(data, ensure_ascii=False)\n",
        "      f.write(jsonString + \"\\n\")\n",
        "      print(jsonString)\n",
        "      k = k + 1\n",
        "    except:\n",
        "      pass\n",
        "    # time.sleep(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0C62O0bNWzi",
        "outputId": "1e09f30f-b96a-4190-96d4-535b1485ff84"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "data_to_csv = []\n",
        "with open(\"Media_Mart.txt\", mode = \"r\", encoding=\"utf8\") as f:\n",
        "  for idx, line in enumerate(f):\n",
        "    data = json.loads(line)\n",
        "    data_to_csv.append(data)\n",
        "print(data_to_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for x in data_to_csv:\n",
        "    print(x)\n",
        "    print(x.keys())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_new = []\n",
        "for pair in data_to_csv:\n",
        "    dt = {}\n",
        "    for key, value in pair.items():\n",
        "        key = str(key).strip().replace('\\n','')\n",
        "        dt[key] = value\n",
        "    data_new.append(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfLLqWjZQMXm"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(data_new).to_csv('mediamart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktMCPdVvQMu9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mediamart.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Thương hiệu\"] = df[\"Thương hiệu\"].apply(lambda line : str(line).strip())\n",
        "df[\"Mã sản phẩm\"] = df[\"Mã sản phẩm\"].apply(lambda line : str(line).strip())\n",
        "df[\"price\"] = df[\"price\"].apply(lambda line : str(line).strip()).apply(lambda line: int(line.split(\"\\n\")[0].strip()[:-2].replace(\".\",\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column, value in df.isnull().sum().sort_values(ascending=True).items():\n",
        "    print(column, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.loc[:, df.isnull().sum() < 144]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum().sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"mediamart.csv\", index=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_new = pd.read_csv(\"mediamart.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_new[\"Màn hình\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Bản sao của Crawl MediaMart.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
